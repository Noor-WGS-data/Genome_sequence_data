# 6. Cleaning up your BAM file with MergeBamAlignments and MarkDuplicatesSpark
###### tags: `2. Main Steps` `tutorials` `markduplicatesspark` `markduplicates` 

> Programs required: GATK

## Background
After you have your aligned the fastq file with the refernce genome (and its BWA index), the output aligned BAM file will be missing all of the information you added to your uBAM (readgroups and marked Illumina adapters). The first step, MergeBamAlignments will merge the information in your uBAM with your aligned BAM and output an aligned bam with readgroups and marked adapters! Then, you will need to mark duplicate reads and sort by coordinate (which can both be done using MarkDuplicatesSPark, step 2). 


#,30,34,45,59,73
## Step 1: MergeBamAlignments

This step merges the alignment information from the product fastq from BWA MEM and the read groups and metadata from uBAM from steps earlier together. 

```
#!/bin/bash
#SBATCH -e errs/%a_mergeBam-%A.err 
#SBATCH -o outs/%a_mergeBam-%A.out 
#SBATCH --mem-per-cpu=20G 
#SBATCH -p scavenger
#SBATCH --cpus-per-task=4 
#SBATCH --mail-type=ALL --mail-user=rp280@duke.edu
#SBATCH -a 19
LL=${SLURM_ARRAY_TASK_ID}

module load GATK/4.1.9.0 

java -Xmx16G -jar $GATK MergeBamAlignment \
-O ../data/2021_09_21_fastq/mergedBAMs/merged_L${LL}.bam \
-R ../ref/dmel-all-chromosome-r6.41.fasta \
-UNMAPPED_BAM ../data/2021_09_21_fastq/uBAMs/unmapped_L${LL}.bam \
-ALIGNED_BAM ../data/2021_09_21_fastq/alignedBAMs/aligned_L${LL}.bam \
-CREATE_INDEX true \
-ADD_MATE_CIGAR true \
-CLIP_ADAPTERS false \
-CLIP_OVERLAPPING_READS true \
-INCLUDE_SECONDARY_ALIGNMENTS true \
-MAX_INSERTIONS_OR_DELETIONS -1 \
-PRIMARY_ALIGNMENT_STRATEGY MostDistant \
-ATTRIBUTES_TO_RETAIN XS \
-TMP_DIR /work/$USER
```
ran into the error
```
 Could not find dictionary next to reference file
```
LMAO WE NEEDED THE DICTIONARY AND INDEX FOR GATK AFTER ALLLLLL
Psych!! It's good that we kept 'em.


## Step 2: Sort and Mark Duplicate Reads

Next, you'll want to mark duplicate reads and sort the SAM file using the GATK command called MarkDuplicatesSpark, which actually sorts the SAM file and marks duplicate reads in one step! The "Mark Duplicates" function of this command will tag duplicate reads, which will be important for future steps like variant calling so duplicates won't be counted twice. The sort function automatically sorts the SAM file by coordinate. 


```
#!/bin/bash
#SBATCH -e errs/%a_markdupspark-%A.err 
#SBATCH -o outs/%a_markdupspark-%A.out 
#SBATCH --mem-per-cpu=20G 
#SBATCH -p scavenger
#SBATCH --cpus-per-task=4 
#SBATCH --mail-type=ALL --mail-user=rp280@duke.edu
#SBATCH -a 19

LL=${SLURM_ARRAY_TASK_ID}

module load GATK/4.1.9.0

java -Xmx16G -jar $GATK MarkDuplicatesSpark \
-I ../data/2021_09_21_fastq/mergedBAMs/merged_L19.bam \
-O ../data/2021_09_21_fastq/aligned_merged_mdup_BAMs/aligned_merged_mdup_L${LL}.bam \
-M ../data/2021_09_21_fastq/aligned_merged_mdup_BAMs/mdup_metrics_L${LL}.txt \
--tmp-dir /work/$USER 
```

 
